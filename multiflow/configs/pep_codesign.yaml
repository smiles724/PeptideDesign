model:
  ckpt_path: ./flow.ckpt
  node_embed_size: 256
  edge_embed_size: 128
  symmetric: False
  transformer_dropout: 0.2
  aatype_pred_num_tokens: 20
  node_features:
    use_mlp: True
    embed_aatype: True
    embed_bb_angle: True
    c_s: ${model.node_embed_size}
    c_pos_emb: 128
    c_timestep_emb: 128
    max_num_res: 2000
    timestep_int: 1000
    embed_chain: False   # no chain information?
    aatype_pred_num_tokens: ${model.aatype_pred_num_tokens}
  edge_features:
    single_bias_transition_n: 2
    c_s: ${model.node_embed_size}
    c_p: ${model.edge_embed_size}
    relpos_k: 64
    feat_dim: 64
    num_bins: 22
    embed_chain: False
    embed_diffuse_mask: True
  ipa:
    c_s: ${model.node_embed_size}
    c_z: ${model.edge_embed_size}
    c_hidden: 16
    no_heads: 8
    no_qk_points: 8
    no_v_points: 12
    seq_tfmr_num_heads: 4
    seq_tfmr_num_layers: 4
    num_blocks: 8
    dropout: 0.0
    fixed_receptor: False
  llm_name: esm2_t33_650M_UR50D
  llm:
    d_model: ${model.node_embed_size}
    n_enc_layers: 3
    n_dec_layers: 3
    use_esm_alphabet: True
    dropout: 0.15
  interpolant:
    min_t: 1.e-2
    t_normalization_clip: 0.9
    rots:
      train_schedule: linear
      sample_schedule: exp
      exp_rate: 10
    trans:
      train_schedule: linear
      sample_schedule: linear
      sigma: 1.0
    seqs:
      num_classes: 20
      simplex_value: 5.0
    sampling:
      num_timesteps: 100

sample:
  ckpt_path: 720000.pt
  output: ./pep_output
  device: cuda
  num_steps: 200   # increase steps?
  num_samples: 80
  llm: False           # TODO:
  x_mirror: False
#  mirror_state:

train:
  debug: false
  project_name: pepflow
  num_workers: 4
  logdir: ./logs
#  num_devices: 4   # number of gpus
  device: 0
  loss_weights:
    trans_loss: 0.5 # 1.0 for dreamfold, 0.05 for yim
    rot_loss: 0.5 # 1.0 for dreamfold, 0.5 for yim
    bb_atom_loss: 0.25
    seqs_loss: 1.0
    seqs_loss_ipa: 1.0
    angle_loss: 1.0
    torsion_loss: 0.5
  max_iters: 40000000
  val_freq: 20000
  batch_size: 16
  accum_grad: 1
  seed: 2024
  max_grad_norm: 100.0
  optimizer:
    type: adam
    lr: 1.e-4 #5.e-4
    weight_decay: 0.0
    beta1: 0.9
    beta2: 0.999
  scheduler:
    type: plateau
    factor: 0.8
    patience: 10
    min_lr: 5.e-6

dataset:
  train:
    type: peprec
    structure_dir: ../pepmerge
    dataset_dir: ../pep_cache
    name: pep_pocket_train
    reset: False
  val:
    type: peprec
    structure_dir: ../pepmerge
    dataset_dir: ../pep_cache
    name: pep_pocket_test
    reset: False